{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samirk08/.pyenv/versions/3.8.18/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/samirk08/.pyenv/versions/3.8.18/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed  \n",
    "import logging\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from functools import partial\n",
    "from fuzzywuzzy import fuzz\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samirk08/.pyenv/versions/3.8.18/lib/python3.8/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Assuming the GPU is available, ensure PyTorch uses it.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "api_key = \"\"  \n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown rice grains, uncooked, agricultural produce.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"/home/samirk08/UROP_SPRING_2024/UserInput/brown husked rice.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4-vision-preview\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Please provide a concise description of the primary item in this image, focusing on its identifiable and classifiable features relevant for customs and tariff purposes. Use no more than 10 words.\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "response_data = response.json()\n",
    "\n",
    "# Extracting and printing only the description from the response\n",
    "user_input = response_data['choices'][0]['message']['content']\n",
    "print(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "df_2023 = pd.read_excel(\"/home/samirk08/UROP_SPRING_2024/UROP IAP 2024/Original Databases/tariff database_202305.xlsx\")\n",
    "brief_descriptions = df_2023['brief_description'].tolist()\n",
    "\n",
    "# pre-compute embeddings for the 2023 dataset\n",
    "embeddings_2023 = torch.load(\"/home/samirk08/UROP_SPRING_2024/UserInput/embeddings.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(50))\n",
    "def ask_gpt(prompt, system_prompt, model_name=\"gpt-4\"):\n",
    "    response = client.chat.completions.create(model=model_name,\n",
    "                                              messages=[\n",
    "                                                  {\"role\": \"system\", \"content\": system_prompt},\n",
    "                                                  {\"role\": \"user\", \"content\": prompt}\n",
    "                                              ],\n",
    "                                              max_tokens=300,\n",
    "                                              temperature=0.0)\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(description, embeddings_2023, df_2023):\n",
    "    description_embedding = model.encode(description, convert_to_tensor=True).to(device)\n",
    "    cosine_scores = util.pytorch_cos_sim(description_embedding, embeddings_2023)\n",
    "    \n",
    "    top_result = torch.argmax(cosine_scores, dim=1)\n",
    "    matched_hs_code = df_2023.iloc[top_result.item()]['hts8']\n",
    "    similarity_score = cosine_scores[0, top_result.item()].item()\n",
    "    matched_description = df_2023.iloc[top_result.item()]['brief_description']  # Fetch the associated description\n",
    "    \n",
    "    return matched_hs_code, similarity_score, matched_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def process_and_compare(user_input):\n",
    "    # enhance description with GPT\n",
    "    system_prompt = \"Enhance this product description to be more detailed and specific for tariff classification purposes:\"\n",
    "    enhanced_description_gpt = ask_gpt(user_input, system_prompt)\n",
    "    \n",
    "    # calculate similarity scores with GPT-enhanced description\n",
    "    gpt_hs_code, gpt_similarity_score, gpt_matched_description = calculate_similarity(enhanced_description_gpt, embeddings_2023, df_2023)\n",
    "    \n",
    "    # calculate similarity scores directly with user input using HF model\n",
    "    hf_hs_code, hf_similarity_score, hf_matched_description = calculate_similarity(user_input, embeddings_2023, df_2023)\n",
    "    \n",
    "    # compare and choose the highest similarity score\n",
    "    if gpt_similarity_score > hf_similarity_score:\n",
    "        chosen_hs_code = gpt_hs_code\n",
    "        final_similarity_score = gpt_similarity_score\n",
    "        method_used = 'GPT'\n",
    "        chosen_description = gpt_matched_description\n",
    "    else:\n",
    "        chosen_hs_code = hf_hs_code\n",
    "        final_similarity_score = hf_similarity_score\n",
    "        method_used = 'HF'\n",
    "        chosen_description = hf_matched_description\n",
    "    \n",
    "    return chosen_hs_code, final_similarity_score, method_used, chosen_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method Used: HF\n",
      "Matched HS Code: 10062040, Similarity Score: 0.6716567277908325\n",
      "Matched Description: Husked (brown) rice, other than Basmati\n"
     ]
    }
   ],
   "source": [
    "# user_input = input(\"Enter a tariff description: \")\n",
    "chosen_hs_code, final_similarity_score, method_used, chosen_description = process_and_compare(user_input)\n",
    "\n",
    "print(f\"Method Used: {method_used}\")\n",
    "print(f\"Matched HS Code: {chosen_hs_code}, Similarity Score: {final_similarity_score}\")\n",
    "print(f\"Matched Description: {chosen_description}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
